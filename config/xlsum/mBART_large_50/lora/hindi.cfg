[model]
name = unified.peft
use_description = False
concatenate_description = False
knowledge_usage = summarization
src_lang = hi_IN
tgt_lang = hi_IN

[peft]
peft_type = LORA
lora_r = 16
lora_alpha = 32
lora_dropout = 0.05

[dataset]
data_store_path = ./data

[seq2seq]
constructor = seq2seq_construction.meta_tuning

[arg_paths]
xlsum = META_TUNING/xlsum_hindi.cfg

[evaluate]
tool = metrics.meta_tuning.evaluator

[bert]
location = facebook/mbart-large-50