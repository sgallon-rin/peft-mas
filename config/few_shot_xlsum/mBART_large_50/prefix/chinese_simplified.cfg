[model]
name = unified.prefixtuning
use_description = False
concatenate_description = False
knowledge_usage = summarization
src_lang = zh_CN
tgt_lang = zh_CN
freeze_plm = True
freeze_prefix = False

[dataset]
data_store_path = ./data

[seq2seq]
constructor = seq2seq_construction.meta_tuning

[arg_paths]
xlsum = META_TUNING/few_shot/xlsum_chinese_simplified.cfg

[evaluate]
tool = metrics.meta_tuning.evaluator

[prefix_tuning]
prefix_sequence_length = 50
mid_dim = 512
prefix_dropout = 0.0

[bert]
location = facebook/mbart-large-50